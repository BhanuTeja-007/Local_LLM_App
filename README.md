# Local_LLM_App
locally hosted, memory-enabled Llama-3 using LM Studio
